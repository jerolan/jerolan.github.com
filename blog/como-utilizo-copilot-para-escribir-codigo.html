<!DOCTYPE html><html lang="es"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-64555470-7"></script><meta property="og:image" content="como-utilizo-copilot-para-escribir-codigo/cover.png" data-next-head=""/><title data-next-head="">¿Cómo utilizo Copilot para escribir código? | Mi forma de integrar la IA en el flujo de trabajo ha evolucionado principalmente con un objetivo claro: reducir la fricción entre el modelo y el contexto real del código.</title><meta name="description" content="Mi forma de integrar la IA en el flujo de trabajo ha evolucionado principalmente con un objetivo claro: reducir la fricción entre el modelo y el contexto real del código." data-next-head=""/><meta property="og:site_name" content="¿Cómo utilizo Copilot para escribir código?" data-next-head=""/><meta property="og:description" content="Mi forma de integrar la IA en el flujo de trabajo ha evolucionado principalmente con un objetivo claro: reducir la fricción entre el modelo y el contexto real del código." data-next-head=""/><meta name="twitter:title" content="¿Cómo utilizo Copilot para escribir código?" data-next-head=""/><meta name="twitter:description" content="Mi forma de integrar la IA en el flujo de trabajo ha evolucionado principalmente con un objetivo claro: reducir la fricción entre el modelo y el contexto real del código." data-next-head=""/><meta name="twitter:card" content="summary_large_image" data-next-head=""/><meta name="twitter:site" content="@sediceyerom" data-next-head=""/><meta name="robots" content="follow, index"/><link rel="preload" href="/_next/static/chunks/94ac632fbb06806a.css" as="style"/><link rel="preload" href="/_next/static/chunks/a7066b969fba8ca0.css" as="style"/><script data-next-head="">
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());

              gtag('config', '398760427', {
                page_path: window.location.pathname,
              });
            </script><script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
              
                gtag('config', 'UA-64555470-7');
              </script><link rel="stylesheet" href="/_next/static/chunks/94ac632fbb06806a.css" data-n-g=""/><link rel="stylesheet" href="/_next/static/chunks/a7066b969fba8ca0.css" data-n-p=""/><noscript data-n-css=""></noscript><script src="/_next/static/chunks/3c10798eb79b6677.js" defer=""></script><script src="/_next/static/chunks/acf108a5e616596f.js" defer=""></script><script src="/_next/static/chunks/18001cb5f4d3fa4b.js" defer=""></script><script src="/_next/static/chunks/8c32ad85dabb85d4.js" defer=""></script><script src="/_next/static/chunks/turbopack-376024341b36e3b3.js" defer=""></script><script src="/_next/static/chunks/4eea677f485f38c0.js" defer=""></script><script src="/_next/static/chunks/0b2f40a9d87d25a3.js" defer=""></script><script src="/_next/static/chunks/turbopack-0ae4e9caa4d56a02.js" defer=""></script><script src="/_next/static/mCc70YjG4xB2b0CTPlWf0/_ssgManifest.js" defer=""></script><script src="/_next/static/mCc70YjG4xB2b0CTPlWf0/_buildManifest.js" defer=""></script></head><body class="antialiased leading-7 bg-white transition-colors duration-500 dark:bg-black dark:text-white"><div id="__next"><main class="px-6 sm:px-8 pt-16 pb-32 max-w-screen-md mx-auto"><header class="pb-12 flex justify-between items-baseline"><div class="space-y-2"><h1 class="font-bold text-3xl sm:text-4xl">Jerome Olvera</h1><h2 class="text-lg sm:text-xl opacity-90 dark:opacity-100">Software Engineer</h2></div><button class="transition-opacity duration-300 hover:bg-transparent bg-opacity-5 dark:bg-opacity-5 border border-opacity-50 rounded p-2 font-medium text-indigo-800 dark:text-yellow-300 bg-indigo-800 dark:bg-yellow-300 border-indigo-800 dark:border-yellow-300 dark:bg-opacity-10 px-2 py-2"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z"></path></svg></button></header><nav class="flex flex-wrap space-x-3 pb-16"><button class="transition-opacity duration-300 hover:bg-transparent bg-opacity-5 dark:bg-opacity-5 border border-opacity-50 rounded p-2 font-medium bg-red-400 dark:bg-red-300 text-red-400 dark:text-red-300 border-red-400 dark:border-red-300 px-4 py-1"><a href="https://github.com/jerolan">Github</a></button><button class="transition-opacity duration-300 hover:bg-transparent bg-opacity-5 dark:bg-opacity-5 border border-opacity-50 rounded p-2 font-medium bg-red-400 dark:bg-red-300 text-red-400 dark:text-red-300 border-red-400 dark:border-red-300 px-4 py-1"><a href="https://twitter.com/sediceyerom">Twitter</a></button><button class="transition-opacity duration-300 hover:bg-transparent bg-opacity-5 dark:bg-opacity-5 border border-opacity-50 rounded p-2 font-medium bg-red-400 dark:bg-red-300 text-red-400 dark:text-red-300 border-red-400 dark:border-red-300 px-4 py-1"><a href="/blog">Blog</a></button></nav><div style="transition-property:top" class="fixed duration-300 left-0 right-0 z-50 bg-white dark:bg-black bg-opacity-80 dark:bg-opacity-80 backdrop-filter backdrop-blur"><div class="px-6 sm:px-8 py-6 sm:py-8 max-w-screen-md mx-auto flex justify-between items-center"><button><span class="font-bold text-md md:text-xl">¿Cómo utilizo Copilot para escribir código?</span></button><button class="transition-opacity duration-300 hover:bg-transparent bg-opacity-5 dark:bg-opacity-5 border border-opacity-50 rounded p-2 font-medium text-indigo-800 dark:text-yellow-300 bg-indigo-800 dark:bg-yellow-300 border-indigo-800 dark:border-yellow-300 dark:bg-opacity-10 px-2 py-2"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z"></path></svg></button></div></div><h1 class="font-bold text-3xl md:text-4xl pb-12">¿Cómo utilizo Copilot para escribir código?</h1><div class="pb-8 space-y-3"><div class="relative h-96 w-full"><img alt="Github Copilot Cover" loading="lazy" decoding="async" data-nimg="fill" class="object-contain object-center" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/como-utilizo-copilot-para-escribir-codigo/cover.png"/></div><p class="text-center text-sm italic opacity-80">Github Copilot Cover</p></div><div class="Markdown-module__GPd7sa__markdown"><h1>¿Cómo utilizo Copilot para escribir código?</h1>
<hr>
<h2>Conceptos clave</h2>
<p>Antes de hablar de flujos de trabajo o trucos, hay conceptos que necesitas dominar si vas a trabajar con agentes de AI. Estos conceptos son lo que separa a alguien que obtiene resultados de mala calidad de alguien que obtiene resultados consistentemente buenos.</p>
<hr>
<h2>Contexto</h2>
<p>El contexto es toda la información que el agente tiene disponible para entenderte y generar algo útil. Yo lo divido en dos tipos: <strong>estático</strong> y <strong>dinámico</strong>.</p>
<h3>Contexto estático</h3>
<p>Es todo lo que se carga <strong>siempre</strong>, desde el inicio de la conversación. El agente ya lo tiene antes de que tú escribas una sola palabra.</p>
<p>En Copilot, los artefactos de contexto estático incluyen:</p>
<ul>
<li><strong><code>AGENTS.md</code></strong> — Instrucciones a nivel de workspace que el agente lee automáticamente.</li>
<li><strong><code>copilot-instructions.md</code></strong> — Instrucciones globales de Copilot que aplican a todas las conversaciones.</li>
<li><strong><code>instructions.md</code></strong> — Instrucciones adicionales que se pueden modularizar por carpeta o propósito.</li>
<li><strong>Archivos de agente</strong> (anteriormente llamados <em>chat modes</em>) — Definiciones de agentes personalizados que incluyen su propio texto de sistema.</li>
</ul>
<p>Piensa en esto como la "memoria base" del agente: le dice quién es, qué reglas seguir, y cómo comportarse en tu proyecto.</p>
<h3>Contexto dinámico</h3>
<p>Es todo lo que el agente va descubriendo solo mientras trabaja. No está predefinido; lo adquiere conforme avanza en la tarea.</p>
<p>Ejemplos:</p>
<ul>
<li><strong>Código fuente</strong> que el agente lee al buscar en el workspace.</li>
<li><strong>Archivos de instrucciones adicionales</strong> que descubre al navegar las carpetas (por ejemplo, archivos <code>instructions.md</code> applyTo específicos).</li>
<li><strong>Archivos <code>AGENTS.md</code> nested</strong> dentro de subcarpetas del proyecto, que el agente encuentra al explorar la estructura.</li>
<li><strong>Resultados de búsquedas</strong>, errores de compilación, salidas de terminal, y cualquier otro artefacto que el agente consulte durante la sesión.</li>
<li><strong>SKILLS y MCPs</strong>, se explicarán más adelante.</li>
</ul>
<hr>
<h2><a href="https://skills.sh/">Skills</a></h2>
<p>Los skills son relativamente nuevos y ganaron popularidad muy rápido por lo fácil que hacen compartir contexto entre proyectos y agentes.</p>
<p>Para mí, los skills cambiaron por completo la forma de trabajar con agentes de AI. Cuando empecé a escribir este artículo, los skills aun no existían. Un mes después, ya definían cómo se desarrolla código con AI.</p>
<p>Un skill es un archivo <code>SKILL.md</code> que encapsula conocimiento de dominio, mejores prácticas y flujos probados para un área específica — testing, diseño técnico, performance, API design, etc.</p>
<p>Antes de los skills, cada proyecto tenía que reinventar sus instrucciones desde cero. Los skills resuelven eso: son portables y reutilizables. Escribes el conocimiento una vez y lo aplicas en cualquier proyecto o agente.</p>
<p>Sobre todo fuera de Github Copilot donde no existían las instructions.md, la gente buscaban una forma de resolver el problema de compartir conocimiento entre proyectos y agentes.</p>
<p>Lo bueno es que los skills son un estándar universal similar a <code>AGENTS.md</code>, así que los puedes usar en el agente que prefieras: Claude Code, OpenCode, GitHub Copilot, etc.</p>
<blockquote>
<p>En Copilot Chat, el soporte de skills pasó de experimental a estable hace relativamente poco de la fecha en la que escribe este artículo.</p>
</blockquote>
<h3>Cómo instalar skills</h3>
<p>Tienes varias formas de agregar skills a tu proyecto:</p>
<p><strong>1. Manual</strong> — Copia el archivo <code>SKILL.md</code> directamente en la carpeta de skills de tu proyecto (e.g., <code>.copilot/skills/mi-skill/SKILL.md</code>). Funciona siempre, sin dependencias.</p>
<p><strong>2. CLI de Vercel (<a href="https://skills.sh/">skills.sh</a>)</strong> — Vercel creó un ecosistema abierto de skills con un CLI que los instala con un solo comando:</p>
<pre><code class="language-bash">npx skills add vercel-labs/agent-skills
</code></pre>
<p>El CLI descarga los archivos del skill desde GitHub y los configura automáticamente para tu agente.</p>
<p><strong>3. CLI de Context7</strong> — <a href="https://context7.com/">Context7</a> también ofrece un catálogo de skills instalables:</p>
<pre><code class="language-bash">npx ctx7 skills install &#x3C;owner/repo>
</code></pre>
<h3>Ejemplos de skills</h3>
<table>
<thead>
<tr>
<th>Skill</th>
<th>Fuente</th>
<th>Qué hace</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>vercel-react-best-practices</code></td>
<td>vercel-labs/agent-skills</td>
<td>40+ reglas de performance para React/Next.js, priorizadas por impacto.</td>
</tr>
<tr>
<td><code>web-design-guidelines</code></td>
<td>vercel-labs/agent-skills</td>
<td>Audita tu UI contra 100+ reglas de accesibilidad, performance y UX.</td>
</tr>
</tbody>
</table>
<h3>Como activar skills de forma predecible</h3>
<p>El agente activa un skill automáticamente cuando detecta que tu tarea coincide con su dominio — no necesitas invocarlo manualmente.</p>
<p>Cuando comencé a usar skills me daba cuenta que otras personas reportaban un efecto similar al mio, que a veces el skill no se activaba o que el agente parecía no usarlo. Incluso VSCode ofrece un setting <code>Use Skill Adherence Prompt</code> para obligar al agente a usar los skills de forma más predecible. Con el tiempo esto es menos común, supongo que con la adopción de los skills y actualizaciones de las herramientas.</p>
<p>Pero un consejo o buena practica para asegurar que esto no te pase es ser muy obvio y claro de cuando se debe activar un skill dentro del header de metadatos, piensa que ese header es lo único que el agente tiene para decidir si el skill aplica o no a la tarea.</p>
<pre><code class="language-markdown">---
name: technical-design-writer
description: |
  Use when the user explicitly asks to:
  - Create, write, or draft a "tech design", "technical design", "diseño técnico", or "technical design document"
  - Document a system design, architecture proposal, or implementation plan using a formal template
  - Follow a standard format for technical decisions with APIs, data models, and operational impact

  DO NOT use for: specs, ADRs only, slide presentations, diagrams only, or informal technical notes.

  This skill enforces a mandatory Markdown template with sections for: Summary, Context, Options, Detailed Design (APIs, data, code, PoC), Metrics, and Consequences.
compatibility: opencode
---
</code></pre>
<hr>
<h2><a href="https://modelcontextprotocol.io/">MCPs (Model Context Protocol)</a></h2>
<p>Los MCPs llevan más tiempo en el ecosistema que los skills y también son parte del contexto dinámico. La diferencia: los skills le dan al agente <em>conocimiento</em>, los MCPs le dan <em>capacidades</em>. Con un MCP el agente puede hacer cosas y consultar fuentes externas que de otra forma no alcanzaría.</p>
<p>Un MCP es un estándar abierto que conecta agentes de AI con herramientas y servicios externos mediante un protocolo uniforme. En la práctica, un MCP server expone <strong>tools</strong> que el agente invoca directamente — buscar documentación, crear issues, consultar APIs, interactuar con bases de datos, etc.</p>
<p>Sin MCPs, un agente solo puede leer archivos y correr comandos en la terminal. Con MCPs, el alcance se multiplica:</p>
<ul>
<li>Acceso a documentación actualizada, en lugar de depender de datos de entrenamiento que pueden estar obsoletos.</li>
<li>Interacción con servicios externos como Jira, GitHub, Confluence, bases de datos, APIs propietarias.</li>
<li>Automatización de flujos: crear issues, abrir PRs, publicar páginas, todo desde el chat.</li>
</ul>
<h3>Ejemplos de MCPs</h3>
<table>
<thead>
<tr>
<th>MCP</th>
<th>Qué habilita</th>
<th>Ejemplo</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><a href="https://context7.com/">Context7</a></strong></td>
<td>Documentación actualizada de +69,000 librerías inyectada directo en el prompt. Elimina alucinaciones de APIs inexistentes.</td>
<td><code>Crea un middleware en Next.js 14 que valide un JWT. use context7</code></td>
</tr>
<tr>
<td><strong>Atlassian</strong></td>
<td>Crea/edita issues en Jira, publica en Confluence, busca con JQL — sin salir del editor.</td>
<td><code>Crea un issue en INS con título "Fix timeout en RFQ"</code></td>
</tr>
<tr>
<td><strong>GitHub</strong></td>
<td>Gestiona repos, issues, PRs, branches desde el agente.</td>
<td><code>Abre un PR con los cambios de esta sesión</code></td>
</tr>
<tr>
<td><strong>Fetch</strong></td>
<td>Lee páginas web arbitrarias para investigar o extraer información.</td>
<td><code>Investiga la API de Stripe en su página de docs</code></td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!tip] Skills vs MCPs</p>
<table>
<thead>
<tr>
<th></th>
<th>Skills</th>
<th>MCPs</th>
</tr>
</thead>
<tbody>
<tr>
<td>Le dan al agente</td>
<td>Conocimiento</td>
<td>Capacidades</td>
</tr>
<tr>
<td>Se activan</td>
<td>Cuando la tarea coincide con su dominio</td>
<td>Cuando el agente necesita una herramienta externa</td>
</tr>
<tr>
<td>Ejemplo</td>
<td>"Usa este patrón para tests"</td>
<td>"Consulta la API de Jira"</td>
</tr>
<tr>
<td>Formato</td>
<td>Archivo <code>SKILL.md</code> en el repo</td>
<td>Server externo con protocolo MCP</td>
</tr>
</tbody>
</table>
</blockquote>
<hr>
<h2>Instructions</h2>
<p>Los <em>instruction files</em> de Copilot son archivos Markdown (<code>.instructions.md</code>) que agregas a tu proyecto para compartir conocimiento entre agentes y modos de programación. Se parecen a los skills en concepto, pero impactan el contexto de forma muy diferente.</p>
<p>Cuando empecé con Copilot, los instructions eran mi herramienta principal. Llenaba archivos con convenciones de código, patrones preferidos, reglas de linting, todo lo que quería que el agente "supiera" de antemano. Y funcionaban bien para establecer una base.</p>
<p>Pero con el tiempo, y sobre todo cuando llegaron los skills, los instructions me fueron dejando de hacer sentido. Los skills ofrecen lo mismo pero de forma más modular y portable. Y lo más importante: se activan solo cuando aplican, en lugar de cargarse siempre. (Obvio según <code>applyTo</code>)</p>
<h3>Instrucciones no escalan</h3>
<p>Puedes tener múltiples archivos de instrucciones, cada uno con un <code>applyTo</code> que define a qué archivos aplica. El problema aparece cuando:</p>
<ol>
<li><strong>Los archivos son demasiado largos</strong> — Decenas de reglas, convenciones y ejemplos.</li>
<li><strong>Aplican a todo</strong> — Usar <code>applyTo: "**"</code> los inyecta en cada conversación, sin importar el contexto.</li>
<li><strong>Se acumulan</strong> — Varios archivos con scope amplio terminan sumando cientos o miles de tokens antes de que escribas una sola palabra.</li>
</ol>
<p>Lo que debería funcionar como contexto dinámico se convierte en contexto estático. Presente siempre, ocupe o no.</p>
<p>La ventana de contexto es finita. Cada token que gastas en instrucciones es un token menos para:</p>
<ul>
<li>Leer tu código fuente.</li>
<li>Analizar errores.</li>
<li>Razonar sobre la tarea.</li>
<li>Generar una respuesta de calidad.</li>
</ul>
<p>Si saturas el contexto con instrucciones genéricas, el agente pierde atención sobre lo que realmente importa: tu tarea actual. Más instrucciones, menos calidad.</p>
<h3>Cómo los uso yo</h3>
<p>Mi caso de uso para los instruction files es casi mínimo. Unos cuantos bullet points — solo para ajustar cositas que la AI repetidamente hace raro o mal. Si detecto un patrón molesto, agrego un solo bullet para corregirlo y no agrego más contexto ahí. La idea es que sean correcciones minimas, no manuales de estilo.</p>
<p>Algo impresionante de los skills es que los puedes distribuir junto otros artefactos de contexto que el agente puede usar, ligeramente fragmentos de código, mas documentos md, etc. Un ejemplo notable es <a href="https://github.com/vercel-labs/agent-skills/tree/main/skills/react-native-skills"><code>vercel-labs/react-native-skills</code></a> el cual es un solo skill que se distribuye junto a otro folder de archivos md que fungen como reglas individuales que el agente puede consultar sin tener que cargar todas al contexto.</p>
<hr>
<h2>Ventana de contexto</h2>
<p>La ventana de contexto es la cantidad máxima de tokens que un modelo puede procesar en una sola conversación. Esto incluye todo: instrucciones del sistema, archivos leídos, tu prompt y la respuesta generada. Dependiendo del modelo que uses, la ventana cambia. Por ejemplo, Claude Opus 4.6 en GitHub Copilot tiene 128K tokens.</p>
<p>Todo lo que hemos hablado (contexto estático, dinámico, skills, MCPs, instructions) compite por espacio dentro de esta misma ventana. Si la llenas rápido con instrucciones genéricas o conversaciones largas, al modelo le queda menos espacio para pensar en lo que le estás pidiendo.</p>
<h3>La regla del 60–70%</h3>
<p>Hay un consenso no formal entre programadores que trabajan con agentes de AI: conviene usar máximo el 60–70% de la ventana de contexto antes de abrir un chat nuevo. Pasado ese punto, la calidad se degrada. El modelo empieza a "olvidar" contexto temprano, pierde precisión y genera respuestas más genéricas.</p>
<blockquote>
<p>[!example] Ejemplo: Claude Opus 4.6 (128K tokens)</p>
<table>
<thead>
<tr>
<th>Rango</th>
<th>Tokens</th>
<th>Estado</th>
</tr>
</thead>
<tbody>
<tr>
<td>0–40%</td>
<td>0–51K</td>
<td>Zona óptima. El modelo tiene espacio de sobra para razonar.</td>
</tr>
<tr>
<td>40–70%</td>
<td>51–90K</td>
<td>Zona funcional. Aún hay calidad, pero empieza a costar.</td>
</tr>
<tr>
<td>70–100%</td>
<td>90–128K</td>
<td>Zona de riesgo. Abre un chat nuevo.</td>
</tr>
</tbody>
</table>
</blockquote>
<h3>Auto-compactación</h3>
<p>Herramientas como Copilot y OpenCode ya tienen mecanismos que auto-compactan el contexto cuando la conversación se acerca al límite. El agente resume o descarta partes anteriores para liberar espacio y seguir funcionando. Es útil, pero no es magia. La compactación pierde detalle, así que no conviene depender de ella como estrategia principal.</p>
<hr>
<h2>Vibe Coding vs Spec Driven</h2>
<p>Originalmente, el concepto de vibe coding como yo lo interpreto es un flujo de desarrollo basado en el <em>Agent Build</em> por defecto de tu herramienta de AI como primera y única instancia. A medida que salen las ideas, usas tu Build mode para ir desarrollando código.</p>
<p>Esto funciona bien. Pero puede llevar al desorden. Recordemos que el contexto es el rey: si tienes buenos skills, buenos prompts y archivos de instrucción justos, el vibe coding va muy bien para proyectos en general.</p>
<p>Para proyectos colaborativos es donde empieza la fricción. Sin embargo, el siguiente escalón natural hacia el orden es el patron <em>Plan Mode → Agent Mode.</em></p>
<p>Todos hemos llegado a la conclusión de que rebotar ideas con AI a veces resulta en resolver el problema tú mismo. <em>El efecto del rubber ducky.</em></p>
<p>Ahora bien, para un desarrollo estandarizado, escalable y consistente, existe Spec Driven Development. Hay muchos approaches que puedes tomar, desde usar solo Plan Mode y guardar eso en un archivo Markdown (Claude Code incluso agregó una funcionalidad para llevar el control de tus tasks en archivos <code>.md</code>), hasta usar frameworks completos como <a href="https://github.com/github/spec-kit">github/spec-kit</a> o <a href="https://github.com/bmadcode/BMAD-METHOD">bmad</a>.</p>
<h3>Mi approach actual</h3>
<p>Mi forma de hacer Spec Driven es a través de un agente que yo mismo personalicé. Unas pocas líneas de instrucción en un agente que me ayuda a crear archivos <code>.md</code> dentro de un folder <code>tasks/</code>, similar a lo que hace Claude Code. Por ahora me es suficiente.</p>
<p>Me pongo a rebotar ideas con mi agente "task-builder", usando referencias de código que mejoren la calidad del plan, y finalmente lo guardo en un archivo de texto <code>.md</code> que me ayuda a llevar un estado de avance de mis actividades.</p>
<p>Literalmente se ve como un TODO list que el mismo agente va palomeando:</p>
<pre><code class="language-markdown"># TASK-042: Migrar servicio de notificaciones a arquitectura serverless

## Contexto

El servicio actual de notificaciones corre en un ECS task dedicado.
Queremos moverlo a Lambda + SQS para reducir costos y simplificar el deploy.

## Tasks

- [x] Definir el esquema de eventos SQS para cada tipo de notificación
- [x] Crear Lambda handler con dead-letter queue
- [x] Migrar templates de correo a S3
- [ ] Implementar retry policy con backoff exponencial
- [ ] Agregar métricas de CloudWatch por tipo de notificación
- [ ] Actualizar integration tests
- [ ] Cleanup: eliminar ECS task definition y security groups viejos

## Notas

- El equipo de infra confirmó que el límite de concurrencia en Lambda es 500.
- Los templates actuales usan Handlebars, se mantienen igual.
</code></pre>
<p>En cuanto tengo mi archivo de tasks escrito usando Opus 4.6, guardado y commiteado, le delego a Codex 5.3 implementar.</p>
<p>Al finalizar, regreso a Opus 4.6 y le hago una pregunta simple: que audite si la tarea realmente está completa o si detecta drift en la implementación.</p>
<p>Si todo sale bien, hago el commit final con los cambios implementados y borro el archivo de tasks. Para mí los task files son disposables: cumplen su función durante el desarrollo y después no los necesito.</p>
<p>El flujo se ve así:</p>
<p><img src="../images/como-utilizo-copilot-para-escribir-codigo/Flujo%20Spec%20Driven%20con%20Agentes.png" alt="[Flujo Spec Driven con Agentes.mermaid]"></p>
<h3>Memorias a largo plazo</h3>
<p>Otra pieza de mi Spec Driven Development son las memorias a largo plazo. Herramientas como spec-kit generan archivos llamados <a href="https://github.com/github/spec-kit?tab=readme-ov-file#2-establish-project-principles"><code>constitucion.md</code></a> donde documentas los pilares del proyecto, y cada tarea generada debe satisfacerlos.</p>
<p>No uso spec-kit completamente, solo algunas partes. Lo que me gusta por ahora es que puede ser una técnica de adopción progresiva, porque la curva de aprendizaje del framework completo puede ser abrumadora.</p>
<p>En mi caso, con mis equipos, el ciclo funciona así: cada que se completa un documento de tareas (que nacen de las HUs de Jira), procuro a través de otro agente llamado "memory-writer" actualizar la documentación técnica o de arquitectura del proyecto. También uso Opus 4.6 para esa documentación.</p>
<p>El ciclo de desarrollo completo entonces se ve así:</p>
<p><img src="../images/como-utilizo-copilot-para-escribir-codigo/SDLC%20Spec%20Driven%20con%20Agentes.png" alt="[SDLC Spec Driven con Agentes.mermaid]"></p>
<p>Sé que existe un plugin para Claude Code que lleva una memoria a largo plazo. De mi lado aún no he implementado algo para hacer RAG de mis memorias, pero pienso que algún MCP que haga <a href="https://github.com/chroma-core/chroma-mcp">Vector DB</a> puede ayudarme a extraer datos específicos sin cargar todo el documento al contexto.</p>
<p>Y aquí de nuevo, context is king.</p>
<blockquote>
<p>[!abstract] Tasks vs Memorias</p>
<table>
<thead>
<tr>
<th></th>
<th>Tasks</th>
<th>Memorias</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ciclo de vida</td>
<td>Nacen, se ejecutan, se borran</td>
<td>Viven con el proyecto</td>
</tr>
<tr>
<td>Mutabilidad</td>
<td>Inmutables (se palomean, no se editan)</td>
<td>Mutables (evolucionan cada iteración)</td>
</tr>
<tr>
<td>Persistencia</td>
<td>Disposables, el historial de git las respalda</td>
<td>Persistentes en el repo</td>
</tr>
<tr>
<td>Ejemplo</td>
<td><code>TASK-042.md</code></td>
<td><code>arquitectura.md</code>, <code>decisions.md</code></td>
</tr>
</tbody>
</table>
</blockquote>
<hr>
<h2>Técnicas multi-agente</h2>
<p>A este punto ya tenemos las bases y las reglas del juego establecidas. Gracias a las specs podemos distribuir el trabajo que no es dependiente entre sí. Los archivos de tasks deben ser ejecutables con la menor dependencia entre sí. Si logras eso, puedes escalar el flujo de trabajo.</p>
<p>GitHub Copilot ofrece la capacidad de correr agentes tanto en la <a href="https://code.visualstudio.com/docs/copilot/agents/cloud-agents">nube</a> como en <a href="https://code.visualstudio.com/docs/copilot/agents/background-agents">background</a>, trabajando en diferentes worktrees. Si nuestras tareas son independientes, podemos pedirle a Copilot que trabaje en diferentes branches y que cuando termine nos mande un PR para que nosotros podamos revisar, aprobar, rechazar o integrar.</p>
<p>Esta misma técnica se integra en herramientas como <a href="https://openai.com/es-ES/codex/">Codex de OpenAI</a>, o herramientas open source como <a href="https://www.conductor.build/">Conductor</a> u <a href="https://opencode.ai/download">OpenCode UI</a>.</p>
<p>Pero no es algo que tú mismo no puedas hacer con algunos comandos e instrucciones personalizadas de agentes. Estas herramientas simplemente son mejores UIs para estas nuevas formas de trabajar.</p>
<p><img src="../images/como-utilizo-copilot-para-escribir-codigo/Flujo%20Multi-Agente%20con%20Worktrees.png" alt="[Flujo Multi-Agente con Worktrees.mermaid]"></p>
<h3>Profundizando en patrones multi-agente</h3>
<p>Desde aquel artículo de Anthropic sobre <a href="https://www.anthropic.com/news/disrupting-AI-espionage">cómo disrumpieron una operación de espionaje con AI</a>, he tratado de aprender y mejorar mis técnicas de desarrollo autónomas multi-agente. En otro artículo más enfocado sobre su <a href="https://www.anthropic.com/engineering/multi-agent-research-system">sistema de investigación multi-agente</a>, Anthropic muestra algunos patrones concretos para este tipo de desarrollo.</p>
<p>Anthropic describe un patrón donde un LeadResearcher orquesta subagentes especializados, cada uno con su propio contexto de ejecución, memoria compartida y un ciclo iterativo de investigación:</p>
<p><img src="../images/como-utilizo-copilot-para-escribir-codigo/Multi-Agent%20Research%20System%20-%20Anthropic.png" alt="[Multi-Agent Research System - Anthropic.mermaid]"></p>
<h4>Workers: subagentes funcionales</h4>
<p>Por ahora mi stack va así. Suelo tener subagentes "workers" encargados de tareas funcionales que no requieran más contexto o investigación: correr tests, extraer output de la consola, ejecutar scripts.</p>
<p>Estos subagentes te ayudan a ahorrar contexto del agente principal, porque cada uno crea su propio contexto de ejecución. El worker hace su trabajo, te regresa el resultado, y el agente principal no gasta tokens en toda esa ejecución intermedia.</p>
<h4>Pipelines: orquestación de alto nivel</h4>
<p>También tengo agentes de alto nivel que se encargan de orquestar. Por ejemplo, un pipeline tipo:</p>
<blockquote>
<p><strong>Challenger → Coder → Refactorer → Reviewer</strong></p>
</blockquote>
<p>Es el flujo de TDD pero orientado a agentes. El Challenger escribe los tests o define los criterios, el Coder implementa, el Refactorer limpia, y el Reviewer audita.</p>
<h4>Routers: especialización por dominio</h4>
<p>También puedes tener modelos router. Un Coder que enruta a diferentes subagentes o skills dependiendo del tipo de tarea. Si quieres que adquiera el arquetipo de FE developer, React developer, QA, Tester, etc., con subagentes creas contextos específicos de ejecución que los vuelven especialistas sobre un subject.</p>
<p><img src="../images/como-utilizo-copilot-para-escribir-codigo/Patron%20Router%20Multi-Agente.png" alt="[Patron Router Multi-Agente.mermaid]"></p>
<h4>Competing Solutions</h4>
<p>Otro patrón que me gusta es abrir múltiples subagentes que implementen la misma solución pero con diferentes modelos o approaches, y al final poner un revisor que escoja la más óptima. Es como hacer un concurso entre agentes: cada uno ataca el problema por su lado, y el reviewer final compara resultados y se queda con el mejor.</p>
<p><img src="../images/como-utilizo-copilot-para-escribir-codigo/Patron%20Competing%20Solutions.png" alt="[Patron Competing Solutions.mermaid]"></p>
<h4>Agentes como pipelines</h4>
<p>Yo ahora miro mis custom agents más como pipelines, como si de un CI/CD se tratara. Son pipelines para orquestar flujos de trabajo, y los skills, la memoria y las tasks son todo lo que los hace ricos en contexto.</p>
<hr>
<h2>Conclusión</h2>
<p>Desde que aparecieron Copilot, GPT-3 y compañía, los flujos de trabajo han evolucionado en una dirección que para mí se resume en: cómo dejar de copiar y pegar con el modelo y, en su lugar, dejar que el modelo esté lo más cerca posible de lo que queremos que logre. Hoy con skills, MCPs, specs, memorias y pipelines multi-agente, esa distancia es cada vez más corta.</p>
<p>Pero lo curioso es que escribir código con agentes de AI es cada vez más parecido a simplemente escribir buen código. Las buenas prácticas de toda la vida siguen siendo las que mandan: código modular, reutilizable, documentado, testeado. Lo que cambió es quién las ejecuta y a qué velocidad.</p>
<p>Al final, la AI solo logró que los ingenieros finalmente escribieran sus pruebas y documentación, segmentaran su tren de pensamiento en pasos claros, y plasmaran todo eso en un recurso que cualquier persona pueda entender.</p>
<p>Qué sorpresa, ¿no?</p>
</div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"¿Cómo utilizo Copilot para escribir código?","date":"2025-12-29","slug":"como-utilizo-copilot-para-escribir-codigo","content":"\u003ch1\u003e¿Cómo utilizo Copilot para escribir código?\u003c/h1\u003e\n\u003chr\u003e\n\u003ch2\u003eConceptos clave\u003c/h2\u003e\n\u003cp\u003eAntes de hablar de flujos de trabajo o trucos, hay conceptos que necesitas dominar si vas a trabajar con agentes de AI. Estos conceptos son lo que separa a alguien que obtiene resultados de mala calidad de alguien que obtiene resultados consistentemente buenos.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eContexto\u003c/h2\u003e\n\u003cp\u003eEl contexto es toda la información que el agente tiene disponible para entenderte y generar algo útil. Yo lo divido en dos tipos: \u003cstrong\u003eestático\u003c/strong\u003e y \u003cstrong\u003edinámico\u003c/strong\u003e.\u003c/p\u003e\n\u003ch3\u003eContexto estático\u003c/h3\u003e\n\u003cp\u003eEs todo lo que se carga \u003cstrong\u003esiempre\u003c/strong\u003e, desde el inicio de la conversación. El agente ya lo tiene antes de que tú escribas una sola palabra.\u003c/p\u003e\n\u003cp\u003eEn Copilot, los artefactos de contexto estático incluyen:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003eAGENTS.md\u003c/code\u003e\u003c/strong\u003e — Instrucciones a nivel de workspace que el agente lee automáticamente.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003ecopilot-instructions.md\u003c/code\u003e\u003c/strong\u003e — Instrucciones globales de Copilot que aplican a todas las conversaciones.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e\u003ccode\u003einstructions.md\u003c/code\u003e\u003c/strong\u003e — Instrucciones adicionales que se pueden modularizar por carpeta o propósito.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eArchivos de agente\u003c/strong\u003e (anteriormente llamados \u003cem\u003echat modes\u003c/em\u003e) — Definiciones de agentes personalizados que incluyen su propio texto de sistema.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePiensa en esto como la \"memoria base\" del agente: le dice quién es, qué reglas seguir, y cómo comportarse en tu proyecto.\u003c/p\u003e\n\u003ch3\u003eContexto dinámico\u003c/h3\u003e\n\u003cp\u003eEs todo lo que el agente va descubriendo solo mientras trabaja. No está predefinido; lo adquiere conforme avanza en la tarea.\u003c/p\u003e\n\u003cp\u003eEjemplos:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCódigo fuente\u003c/strong\u003e que el agente lee al buscar en el workspace.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eArchivos de instrucciones adicionales\u003c/strong\u003e que descubre al navegar las carpetas (por ejemplo, archivos \u003ccode\u003einstructions.md\u003c/code\u003e applyTo específicos).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eArchivos \u003ccode\u003eAGENTS.md\u003c/code\u003e nested\u003c/strong\u003e dentro de subcarpetas del proyecto, que el agente encuentra al explorar la estructura.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eResultados de búsquedas\u003c/strong\u003e, errores de compilación, salidas de terminal, y cualquier otro artefacto que el agente consulte durante la sesión.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSKILLS y MCPs\u003c/strong\u003e, se explicarán más adelante.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2\u003e\u003ca href=\"https://skills.sh/\"\u003eSkills\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eLos skills son relativamente nuevos y ganaron popularidad muy rápido por lo fácil que hacen compartir contexto entre proyectos y agentes.\u003c/p\u003e\n\u003cp\u003ePara mí, los skills cambiaron por completo la forma de trabajar con agentes de AI. Cuando empecé a escribir este artículo, los skills aun no existían. Un mes después, ya definían cómo se desarrolla código con AI.\u003c/p\u003e\n\u003cp\u003eUn skill es un archivo \u003ccode\u003eSKILL.md\u003c/code\u003e que encapsula conocimiento de dominio, mejores prácticas y flujos probados para un área específica — testing, diseño técnico, performance, API design, etc.\u003c/p\u003e\n\u003cp\u003eAntes de los skills, cada proyecto tenía que reinventar sus instrucciones desde cero. Los skills resuelven eso: son portables y reutilizables. Escribes el conocimiento una vez y lo aplicas en cualquier proyecto o agente.\u003c/p\u003e\n\u003cp\u003eSobre todo fuera de Github Copilot donde no existían las instructions.md, la gente buscaban una forma de resolver el problema de compartir conocimiento entre proyectos y agentes.\u003c/p\u003e\n\u003cp\u003eLo bueno es que los skills son un estándar universal similar a \u003ccode\u003eAGENTS.md\u003c/code\u003e, así que los puedes usar en el agente que prefieras: Claude Code, OpenCode, GitHub Copilot, etc.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eEn Copilot Chat, el soporte de skills pasó de experimental a estable hace relativamente poco de la fecha en la que escribe este artículo.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003eCómo instalar skills\u003c/h3\u003e\n\u003cp\u003eTienes varias formas de agregar skills a tu proyecto:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. Manual\u003c/strong\u003e — Copia el archivo \u003ccode\u003eSKILL.md\u003c/code\u003e directamente en la carpeta de skills de tu proyecto (e.g., \u003ccode\u003e.copilot/skills/mi-skill/SKILL.md\u003c/code\u003e). Funciona siempre, sin dependencias.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. CLI de Vercel (\u003ca href=\"https://skills.sh/\"\u003eskills.sh\u003c/a\u003e)\u003c/strong\u003e — Vercel creó un ecosistema abierto de skills con un CLI que los instala con un solo comando:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003enpx skills add vercel-labs/agent-skills\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEl CLI descarga los archivos del skill desde GitHub y los configura automáticamente para tu agente.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. CLI de Context7\u003c/strong\u003e — \u003ca href=\"https://context7.com/\"\u003eContext7\u003c/a\u003e también ofrece un catálogo de skills instalables:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003enpx ctx7 skills install \u0026#x3C;owner/repo\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eEjemplos de skills\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eSkill\u003c/th\u003e\n\u003cth\u003eFuente\u003c/th\u003e\n\u003cth\u003eQué hace\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003evercel-react-best-practices\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003evercel-labs/agent-skills\u003c/td\u003e\n\u003ctd\u003e40+ reglas de performance para React/Next.js, priorizadas por impacto.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eweb-design-guidelines\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003evercel-labs/agent-skills\u003c/td\u003e\n\u003ctd\u003eAudita tu UI contra 100+ reglas de accesibilidad, performance y UX.\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003eComo activar skills de forma predecible\u003c/h3\u003e\n\u003cp\u003eEl agente activa un skill automáticamente cuando detecta que tu tarea coincide con su dominio — no necesitas invocarlo manualmente.\u003c/p\u003e\n\u003cp\u003eCuando comencé a usar skills me daba cuenta que otras personas reportaban un efecto similar al mio, que a veces el skill no se activaba o que el agente parecía no usarlo. Incluso VSCode ofrece un setting \u003ccode\u003eUse Skill Adherence Prompt\u003c/code\u003e para obligar al agente a usar los skills de forma más predecible. Con el tiempo esto es menos común, supongo que con la adopción de los skills y actualizaciones de las herramientas.\u003c/p\u003e\n\u003cp\u003ePero un consejo o buena practica para asegurar que esto no te pase es ser muy obvio y claro de cuando se debe activar un skill dentro del header de metadatos, piensa que ese header es lo único que el agente tiene para decidir si el skill aplica o no a la tarea.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-markdown\"\u003e---\nname: technical-design-writer\ndescription: |\n  Use when the user explicitly asks to:\n  - Create, write, or draft a \"tech design\", \"technical design\", \"diseño técnico\", or \"technical design document\"\n  - Document a system design, architecture proposal, or implementation plan using a formal template\n  - Follow a standard format for technical decisions with APIs, data models, and operational impact\n\n  DO NOT use for: specs, ADRs only, slide presentations, diagrams only, or informal technical notes.\n\n  This skill enforces a mandatory Markdown template with sections for: Summary, Context, Options, Detailed Design (APIs, data, code, PoC), Metrics, and Consequences.\ncompatibility: opencode\n---\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e\u003ca href=\"https://modelcontextprotocol.io/\"\u003eMCPs (Model Context Protocol)\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eLos MCPs llevan más tiempo en el ecosistema que los skills y también son parte del contexto dinámico. La diferencia: los skills le dan al agente \u003cem\u003econocimiento\u003c/em\u003e, los MCPs le dan \u003cem\u003ecapacidades\u003c/em\u003e. Con un MCP el agente puede hacer cosas y consultar fuentes externas que de otra forma no alcanzaría.\u003c/p\u003e\n\u003cp\u003eUn MCP es un estándar abierto que conecta agentes de AI con herramientas y servicios externos mediante un protocolo uniforme. En la práctica, un MCP server expone \u003cstrong\u003etools\u003c/strong\u003e que el agente invoca directamente — buscar documentación, crear issues, consultar APIs, interactuar con bases de datos, etc.\u003c/p\u003e\n\u003cp\u003eSin MCPs, un agente solo puede leer archivos y correr comandos en la terminal. Con MCPs, el alcance se multiplica:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAcceso a documentación actualizada, en lugar de depender de datos de entrenamiento que pueden estar obsoletos.\u003c/li\u003e\n\u003cli\u003eInteracción con servicios externos como Jira, GitHub, Confluence, bases de datos, APIs propietarias.\u003c/li\u003e\n\u003cli\u003eAutomatización de flujos: crear issues, abrir PRs, publicar páginas, todo desde el chat.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eEjemplos de MCPs\u003c/h3\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eMCP\u003c/th\u003e\n\u003cth\u003eQué habilita\u003c/th\u003e\n\u003cth\u003eEjemplo\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003e\u003ca href=\"https://context7.com/\"\u003eContext7\u003c/a\u003e\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eDocumentación actualizada de +69,000 librerías inyectada directo en el prompt. Elimina alucinaciones de APIs inexistentes.\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eCrea un middleware en Next.js 14 que valide un JWT. use context7\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eAtlassian\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eCrea/edita issues en Jira, publica en Confluence, busca con JQL — sin salir del editor.\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eCrea un issue en INS con título \"Fix timeout en RFQ\"\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eGitHub\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eGestiona repos, issues, PRs, branches desde el agente.\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eAbre un PR con los cambios de esta sesión\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eFetch\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eLee páginas web arbitrarias para investigar o extraer información.\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eInvestiga la API de Stripe en su página de docs\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cblockquote\u003e\n\u003cp\u003e[!tip] Skills vs MCPs\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eSkills\u003c/th\u003e\n\u003cth\u003eMCPs\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eLe dan al agente\u003c/td\u003e\n\u003ctd\u003eConocimiento\u003c/td\u003e\n\u003ctd\u003eCapacidades\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSe activan\u003c/td\u003e\n\u003ctd\u003eCuando la tarea coincide con su dominio\u003c/td\u003e\n\u003ctd\u003eCuando el agente necesita una herramienta externa\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEjemplo\u003c/td\u003e\n\u003ctd\u003e\"Usa este patrón para tests\"\u003c/td\u003e\n\u003ctd\u003e\"Consulta la API de Jira\"\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eFormato\u003c/td\u003e\n\u003ctd\u003eArchivo \u003ccode\u003eSKILL.md\u003c/code\u003e en el repo\u003c/td\u003e\n\u003ctd\u003eServer externo con protocolo MCP\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003eInstructions\u003c/h2\u003e\n\u003cp\u003eLos \u003cem\u003einstruction files\u003c/em\u003e de Copilot son archivos Markdown (\u003ccode\u003e.instructions.md\u003c/code\u003e) que agregas a tu proyecto para compartir conocimiento entre agentes y modos de programación. Se parecen a los skills en concepto, pero impactan el contexto de forma muy diferente.\u003c/p\u003e\n\u003cp\u003eCuando empecé con Copilot, los instructions eran mi herramienta principal. Llenaba archivos con convenciones de código, patrones preferidos, reglas de linting, todo lo que quería que el agente \"supiera\" de antemano. Y funcionaban bien para establecer una base.\u003c/p\u003e\n\u003cp\u003ePero con el tiempo, y sobre todo cuando llegaron los skills, los instructions me fueron dejando de hacer sentido. Los skills ofrecen lo mismo pero de forma más modular y portable. Y lo más importante: se activan solo cuando aplican, en lugar de cargarse siempre. (Obvio según \u003ccode\u003eapplyTo\u003c/code\u003e)\u003c/p\u003e\n\u003ch3\u003eInstrucciones no escalan\u003c/h3\u003e\n\u003cp\u003ePuedes tener múltiples archivos de instrucciones, cada uno con un \u003ccode\u003eapplyTo\u003c/code\u003e que define a qué archivos aplica. El problema aparece cuando:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eLos archivos son demasiado largos\u003c/strong\u003e — Decenas de reglas, convenciones y ejemplos.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAplican a todo\u003c/strong\u003e — Usar \u003ccode\u003eapplyTo: \"**\"\u003c/code\u003e los inyecta en cada conversación, sin importar el contexto.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSe acumulan\u003c/strong\u003e — Varios archivos con scope amplio terminan sumando cientos o miles de tokens antes de que escribas una sola palabra.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eLo que debería funcionar como contexto dinámico se convierte en contexto estático. Presente siempre, ocupe o no.\u003c/p\u003e\n\u003cp\u003eLa ventana de contexto es finita. Cada token que gastas en instrucciones es un token menos para:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLeer tu código fuente.\u003c/li\u003e\n\u003cli\u003eAnalizar errores.\u003c/li\u003e\n\u003cli\u003eRazonar sobre la tarea.\u003c/li\u003e\n\u003cli\u003eGenerar una respuesta de calidad.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSi saturas el contexto con instrucciones genéricas, el agente pierde atención sobre lo que realmente importa: tu tarea actual. Más instrucciones, menos calidad.\u003c/p\u003e\n\u003ch3\u003eCómo los uso yo\u003c/h3\u003e\n\u003cp\u003eMi caso de uso para los instruction files es casi mínimo. Unos cuantos bullet points — solo para ajustar cositas que la AI repetidamente hace raro o mal. Si detecto un patrón molesto, agrego un solo bullet para corregirlo y no agrego más contexto ahí. La idea es que sean correcciones minimas, no manuales de estilo.\u003c/p\u003e\n\u003cp\u003eAlgo impresionante de los skills es que los puedes distribuir junto otros artefactos de contexto que el agente puede usar, ligeramente fragmentos de código, mas documentos md, etc. Un ejemplo notable es \u003ca href=\"https://github.com/vercel-labs/agent-skills/tree/main/skills/react-native-skills\"\u003e\u003ccode\u003evercel-labs/react-native-skills\u003c/code\u003e\u003c/a\u003e el cual es un solo skill que se distribuye junto a otro folder de archivos md que fungen como reglas individuales que el agente puede consultar sin tener que cargar todas al contexto.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eVentana de contexto\u003c/h2\u003e\n\u003cp\u003eLa ventana de contexto es la cantidad máxima de tokens que un modelo puede procesar en una sola conversación. Esto incluye todo: instrucciones del sistema, archivos leídos, tu prompt y la respuesta generada. Dependiendo del modelo que uses, la ventana cambia. Por ejemplo, Claude Opus 4.6 en GitHub Copilot tiene 128K tokens.\u003c/p\u003e\n\u003cp\u003eTodo lo que hemos hablado (contexto estático, dinámico, skills, MCPs, instructions) compite por espacio dentro de esta misma ventana. Si la llenas rápido con instrucciones genéricas o conversaciones largas, al modelo le queda menos espacio para pensar en lo que le estás pidiendo.\u003c/p\u003e\n\u003ch3\u003eLa regla del 60–70%\u003c/h3\u003e\n\u003cp\u003eHay un consenso no formal entre programadores que trabajan con agentes de AI: conviene usar máximo el 60–70% de la ventana de contexto antes de abrir un chat nuevo. Pasado ese punto, la calidad se degrada. El modelo empieza a \"olvidar\" contexto temprano, pierde precisión y genera respuestas más genéricas.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e[!example] Ejemplo: Claude Opus 4.6 (128K tokens)\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eRango\u003c/th\u003e\n\u003cth\u003eTokens\u003c/th\u003e\n\u003cth\u003eEstado\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e0–40%\u003c/td\u003e\n\u003ctd\u003e0–51K\u003c/td\u003e\n\u003ctd\u003eZona óptima. El modelo tiene espacio de sobra para razonar.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e40–70%\u003c/td\u003e\n\u003ctd\u003e51–90K\u003c/td\u003e\n\u003ctd\u003eZona funcional. Aún hay calidad, pero empieza a costar.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e70–100%\u003c/td\u003e\n\u003ctd\u003e90–128K\u003c/td\u003e\n\u003ctd\u003eZona de riesgo. Abre un chat nuevo.\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003eAuto-compactación\u003c/h3\u003e\n\u003cp\u003eHerramientas como Copilot y OpenCode ya tienen mecanismos que auto-compactan el contexto cuando la conversación se acerca al límite. El agente resume o descarta partes anteriores para liberar espacio y seguir funcionando. Es útil, pero no es magia. La compactación pierde detalle, así que no conviene depender de ella como estrategia principal.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eVibe Coding vs Spec Driven\u003c/h2\u003e\n\u003cp\u003eOriginalmente, el concepto de vibe coding como yo lo interpreto es un flujo de desarrollo basado en el \u003cem\u003eAgent Build\u003c/em\u003e por defecto de tu herramienta de AI como primera y única instancia. A medida que salen las ideas, usas tu Build mode para ir desarrollando código.\u003c/p\u003e\n\u003cp\u003eEsto funciona bien. Pero puede llevar al desorden. Recordemos que el contexto es el rey: si tienes buenos skills, buenos prompts y archivos de instrucción justos, el vibe coding va muy bien para proyectos en general.\u003c/p\u003e\n\u003cp\u003ePara proyectos colaborativos es donde empieza la fricción. Sin embargo, el siguiente escalón natural hacia el orden es el patron \u003cem\u003ePlan Mode → Agent Mode.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eTodos hemos llegado a la conclusión de que rebotar ideas con AI a veces resulta en resolver el problema tú mismo. \u003cem\u003eEl efecto del rubber ducky.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAhora bien, para un desarrollo estandarizado, escalable y consistente, existe Spec Driven Development. Hay muchos approaches que puedes tomar, desde usar solo Plan Mode y guardar eso en un archivo Markdown (Claude Code incluso agregó una funcionalidad para llevar el control de tus tasks en archivos \u003ccode\u003e.md\u003c/code\u003e), hasta usar frameworks completos como \u003ca href=\"https://github.com/github/spec-kit\"\u003egithub/spec-kit\u003c/a\u003e o \u003ca href=\"https://github.com/bmadcode/BMAD-METHOD\"\u003ebmad\u003c/a\u003e.\u003c/p\u003e\n\u003ch3\u003eMi approach actual\u003c/h3\u003e\n\u003cp\u003eMi forma de hacer Spec Driven es a través de un agente que yo mismo personalicé. Unas pocas líneas de instrucción en un agente que me ayuda a crear archivos \u003ccode\u003e.md\u003c/code\u003e dentro de un folder \u003ccode\u003etasks/\u003c/code\u003e, similar a lo que hace Claude Code. Por ahora me es suficiente.\u003c/p\u003e\n\u003cp\u003eMe pongo a rebotar ideas con mi agente \"task-builder\", usando referencias de código que mejoren la calidad del plan, y finalmente lo guardo en un archivo de texto \u003ccode\u003e.md\u003c/code\u003e que me ayuda a llevar un estado de avance de mis actividades.\u003c/p\u003e\n\u003cp\u003eLiteralmente se ve como un TODO list que el mismo agente va palomeando:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-markdown\"\u003e# TASK-042: Migrar servicio de notificaciones a arquitectura serverless\n\n## Contexto\n\nEl servicio actual de notificaciones corre en un ECS task dedicado.\nQueremos moverlo a Lambda + SQS para reducir costos y simplificar el deploy.\n\n## Tasks\n\n- [x] Definir el esquema de eventos SQS para cada tipo de notificación\n- [x] Crear Lambda handler con dead-letter queue\n- [x] Migrar templates de correo a S3\n- [ ] Implementar retry policy con backoff exponencial\n- [ ] Agregar métricas de CloudWatch por tipo de notificación\n- [ ] Actualizar integration tests\n- [ ] Cleanup: eliminar ECS task definition y security groups viejos\n\n## Notas\n\n- El equipo de infra confirmó que el límite de concurrencia en Lambda es 500.\n- Los templates actuales usan Handlebars, se mantienen igual.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEn cuanto tengo mi archivo de tasks escrito usando Opus 4.6, guardado y commiteado, le delego a Codex 5.3 implementar.\u003c/p\u003e\n\u003cp\u003eAl finalizar, regreso a Opus 4.6 y le hago una pregunta simple: que audite si la tarea realmente está completa o si detecta drift en la implementación.\u003c/p\u003e\n\u003cp\u003eSi todo sale bien, hago el commit final con los cambios implementados y borro el archivo de tasks. Para mí los task files son disposables: cumplen su función durante el desarrollo y después no los necesito.\u003c/p\u003e\n\u003cp\u003eEl flujo se ve así:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../images/como-utilizo-copilot-para-escribir-codigo/Flujo%20Spec%20Driven%20con%20Agentes.png\" alt=\"[Flujo Spec Driven con Agentes.mermaid]\"\u003e\u003c/p\u003e\n\u003ch3\u003eMemorias a largo plazo\u003c/h3\u003e\n\u003cp\u003eOtra pieza de mi Spec Driven Development son las memorias a largo plazo. Herramientas como spec-kit generan archivos llamados \u003ca href=\"https://github.com/github/spec-kit?tab=readme-ov-file#2-establish-project-principles\"\u003e\u003ccode\u003econstitucion.md\u003c/code\u003e\u003c/a\u003e donde documentas los pilares del proyecto, y cada tarea generada debe satisfacerlos.\u003c/p\u003e\n\u003cp\u003eNo uso spec-kit completamente, solo algunas partes. Lo que me gusta por ahora es que puede ser una técnica de adopción progresiva, porque la curva de aprendizaje del framework completo puede ser abrumadora.\u003c/p\u003e\n\u003cp\u003eEn mi caso, con mis equipos, el ciclo funciona así: cada que se completa un documento de tareas (que nacen de las HUs de Jira), procuro a través de otro agente llamado \"memory-writer\" actualizar la documentación técnica o de arquitectura del proyecto. También uso Opus 4.6 para esa documentación.\u003c/p\u003e\n\u003cp\u003eEl ciclo de desarrollo completo entonces se ve así:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../images/como-utilizo-copilot-para-escribir-codigo/SDLC%20Spec%20Driven%20con%20Agentes.png\" alt=\"[SDLC Spec Driven con Agentes.mermaid]\"\u003e\u003c/p\u003e\n\u003cp\u003eSé que existe un plugin para Claude Code que lleva una memoria a largo plazo. De mi lado aún no he implementado algo para hacer RAG de mis memorias, pero pienso que algún MCP que haga \u003ca href=\"https://github.com/chroma-core/chroma-mcp\"\u003eVector DB\u003c/a\u003e puede ayudarme a extraer datos específicos sin cargar todo el documento al contexto.\u003c/p\u003e\n\u003cp\u003eY aquí de nuevo, context is king.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e[!abstract] Tasks vs Memorias\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eTasks\u003c/th\u003e\n\u003cth\u003eMemorias\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCiclo de vida\u003c/td\u003e\n\u003ctd\u003eNacen, se ejecutan, se borran\u003c/td\u003e\n\u003ctd\u003eViven con el proyecto\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMutabilidad\u003c/td\u003e\n\u003ctd\u003eInmutables (se palomean, no se editan)\u003c/td\u003e\n\u003ctd\u003eMutables (evolucionan cada iteración)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePersistencia\u003c/td\u003e\n\u003ctd\u003eDisposables, el historial de git las respalda\u003c/td\u003e\n\u003ctd\u003ePersistentes en el repo\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEjemplo\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eTASK-042.md\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003earquitectura.md\u003c/code\u003e, \u003ccode\u003edecisions.md\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2\u003eTécnicas multi-agente\u003c/h2\u003e\n\u003cp\u003eA este punto ya tenemos las bases y las reglas del juego establecidas. Gracias a las specs podemos distribuir el trabajo que no es dependiente entre sí. Los archivos de tasks deben ser ejecutables con la menor dependencia entre sí. Si logras eso, puedes escalar el flujo de trabajo.\u003c/p\u003e\n\u003cp\u003eGitHub Copilot ofrece la capacidad de correr agentes tanto en la \u003ca href=\"https://code.visualstudio.com/docs/copilot/agents/cloud-agents\"\u003enube\u003c/a\u003e como en \u003ca href=\"https://code.visualstudio.com/docs/copilot/agents/background-agents\"\u003ebackground\u003c/a\u003e, trabajando en diferentes worktrees. Si nuestras tareas son independientes, podemos pedirle a Copilot que trabaje en diferentes branches y que cuando termine nos mande un PR para que nosotros podamos revisar, aprobar, rechazar o integrar.\u003c/p\u003e\n\u003cp\u003eEsta misma técnica se integra en herramientas como \u003ca href=\"https://openai.com/es-ES/codex/\"\u003eCodex de OpenAI\u003c/a\u003e, o herramientas open source como \u003ca href=\"https://www.conductor.build/\"\u003eConductor\u003c/a\u003e u \u003ca href=\"https://opencode.ai/download\"\u003eOpenCode UI\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePero no es algo que tú mismo no puedas hacer con algunos comandos e instrucciones personalizadas de agentes. Estas herramientas simplemente son mejores UIs para estas nuevas formas de trabajar.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../images/como-utilizo-copilot-para-escribir-codigo/Flujo%20Multi-Agente%20con%20Worktrees.png\" alt=\"[Flujo Multi-Agente con Worktrees.mermaid]\"\u003e\u003c/p\u003e\n\u003ch3\u003eProfundizando en patrones multi-agente\u003c/h3\u003e\n\u003cp\u003eDesde aquel artículo de Anthropic sobre \u003ca href=\"https://www.anthropic.com/news/disrupting-AI-espionage\"\u003ecómo disrumpieron una operación de espionaje con AI\u003c/a\u003e, he tratado de aprender y mejorar mis técnicas de desarrollo autónomas multi-agente. En otro artículo más enfocado sobre su \u003ca href=\"https://www.anthropic.com/engineering/multi-agent-research-system\"\u003esistema de investigación multi-agente\u003c/a\u003e, Anthropic muestra algunos patrones concretos para este tipo de desarrollo.\u003c/p\u003e\n\u003cp\u003eAnthropic describe un patrón donde un LeadResearcher orquesta subagentes especializados, cada uno con su propio contexto de ejecución, memoria compartida y un ciclo iterativo de investigación:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../images/como-utilizo-copilot-para-escribir-codigo/Multi-Agent%20Research%20System%20-%20Anthropic.png\" alt=\"[Multi-Agent Research System - Anthropic.mermaid]\"\u003e\u003c/p\u003e\n\u003ch4\u003eWorkers: subagentes funcionales\u003c/h4\u003e\n\u003cp\u003ePor ahora mi stack va así. Suelo tener subagentes \"workers\" encargados de tareas funcionales que no requieran más contexto o investigación: correr tests, extraer output de la consola, ejecutar scripts.\u003c/p\u003e\n\u003cp\u003eEstos subagentes te ayudan a ahorrar contexto del agente principal, porque cada uno crea su propio contexto de ejecución. El worker hace su trabajo, te regresa el resultado, y el agente principal no gasta tokens en toda esa ejecución intermedia.\u003c/p\u003e\n\u003ch4\u003ePipelines: orquestación de alto nivel\u003c/h4\u003e\n\u003cp\u003eTambién tengo agentes de alto nivel que se encargan de orquestar. Por ejemplo, un pipeline tipo:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eChallenger → Coder → Refactorer → Reviewer\u003c/strong\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eEs el flujo de TDD pero orientado a agentes. El Challenger escribe los tests o define los criterios, el Coder implementa, el Refactorer limpia, y el Reviewer audita.\u003c/p\u003e\n\u003ch4\u003eRouters: especialización por dominio\u003c/h4\u003e\n\u003cp\u003eTambién puedes tener modelos router. Un Coder que enruta a diferentes subagentes o skills dependiendo del tipo de tarea. Si quieres que adquiera el arquetipo de FE developer, React developer, QA, Tester, etc., con subagentes creas contextos específicos de ejecución que los vuelven especialistas sobre un subject.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../images/como-utilizo-copilot-para-escribir-codigo/Patron%20Router%20Multi-Agente.png\" alt=\"[Patron Router Multi-Agente.mermaid]\"\u003e\u003c/p\u003e\n\u003ch4\u003eCompeting Solutions\u003c/h4\u003e\n\u003cp\u003eOtro patrón que me gusta es abrir múltiples subagentes que implementen la misma solución pero con diferentes modelos o approaches, y al final poner un revisor que escoja la más óptima. Es como hacer un concurso entre agentes: cada uno ataca el problema por su lado, y el reviewer final compara resultados y se queda con el mejor.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"../images/como-utilizo-copilot-para-escribir-codigo/Patron%20Competing%20Solutions.png\" alt=\"[Patron Competing Solutions.mermaid]\"\u003e\u003c/p\u003e\n\u003ch4\u003eAgentes como pipelines\u003c/h4\u003e\n\u003cp\u003eYo ahora miro mis custom agents más como pipelines, como si de un CI/CD se tratara. Son pipelines para orquestar flujos de trabajo, y los skills, la memoria y las tasks son todo lo que los hace ricos en contexto.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003eConclusión\u003c/h2\u003e\n\u003cp\u003eDesde que aparecieron Copilot, GPT-3 y compañía, los flujos de trabajo han evolucionado en una dirección que para mí se resume en: cómo dejar de copiar y pegar con el modelo y, en su lugar, dejar que el modelo esté lo más cerca posible de lo que queremos que logre. Hoy con skills, MCPs, specs, memorias y pipelines multi-agente, esa distancia es cada vez más corta.\u003c/p\u003e\n\u003cp\u003ePero lo curioso es que escribir código con agentes de AI es cada vez más parecido a simplemente escribir buen código. Las buenas prácticas de toda la vida siguen siendo las que mandan: código modular, reutilizable, documentado, testeado. Lo que cambió es quién las ejecuta y a qué velocidad.\u003c/p\u003e\n\u003cp\u003eAl final, la AI solo logró que los ingenieros finalmente escribieran sus pruebas y documentación, segmentaran su tren de pensamiento en pasos claros, y plasmaran todo eso en un recurso que cualquier persona pueda entender.\u003c/p\u003e\n\u003cp\u003eQué sorpresa, ¿no?\u003c/p\u003e\n","cover":{"alt":"Github Copilot Cover","src":"como-utilizo-copilot-para-escribir-codigo/cover.png"},"excerpt":"Mi forma de integrar la IA en el flujo de trabajo ha evolucionado principalmente con un objetivo claro: reducir la fricción entre el modelo y el contexto real del código."}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"como-utilizo-copilot-para-escribir-codigo"},"buildId":"mCc70YjG4xB2b0CTPlWf0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>